# ğŸ¯ Feature Extraction Guide for ML Training

## ğŸ“Š æ•°æ®æ¦‚è§ˆ

ä½ ç°åœ¨æœ‰ **3 ä¸ªç‰¹å¾æ–‡ä»¶** å¯ä»¥ç”¨äºè®­ç»ƒæ¨¡å‹ï¼š

| æ–‡ä»¶ | ç²’åº¦ | æ ·æœ¬æ•° | ç‰¹å¾æ•° | é€‚ç”¨æ¨¡å‹ |
|------|------|--------|--------|----------|
| `combined_au_features.csv` | **Frame-level** (å¸§çº§åˆ«) | 25,920 å¸§ | 27 | LSTM, RNN, Transformer, CNN |
| `clip_features_simple.csv` | **Clip-level** (ç‰‡æ®µçº§åˆ«) | 42 clips | 138 | ä¼ ç»ŸML (RF, XGBoost, SVM) |
| `clip_features_full.csv` | **Clip-level** (ç‰‡æ®µçº§åˆ«) | 42 clips | 562 | ä¼ ç»ŸML + æ·±åº¦å­¦ä¹  |

---

## 1ï¸âƒ£ Frame-level Features (å¸§çº§åˆ«ç‰¹å¾)
**æ–‡ä»¶**: `combined_au_features.csv`

### åŸå§‹ç‰¹å¾ (27ä¸ª)

#### Action Units (20ä¸ª)
æ¯ä¸ªAUçš„æ¿€æ´»å¼ºåº¦ï¼Œå€¼åŸŸ: [0.0, 1.0]

| AU | æè¿° | ä½ç½® |
|----|------|------|
| **AU01** | Inner Brow Raiser (å†…çœ‰ä¸ŠæŠ¬) | çœ‰æ¯› |
| **AU02** | Outer Brow Raiser (å¤–çœ‰ä¸ŠæŠ¬) | çœ‰æ¯› |
| **AU04** | Brow Lowerer (çš±çœ‰) | çœ‰æ¯› |
| **AU05** | Upper Lid Raiser (ä¸Šçœ¼ç‘æå‡) | çœ¼ç› |
| **AU06** | Cheek Raiser (é¢§éª¨æå‡) | è„¸é¢Š |
| **AU07** | Lid Tightener (çœ¼ç›çœ¯èµ·) | çœ¼ç› |
| **AU09** | Nose Wrinkler (çš±é¼») | é¼»å­ |
| **AU10** | Upper Lip Raiser (ä¸Šå”‡ä¸Šæ) | å˜´éƒ¨ |
| **AU11** | Nasolabial Deepener (é¼»å”‡æ²ŸåŠ æ·±) | å˜´éƒ¨ |
| **AU12** | Lip Corner Puller (å˜´è§’ä¸Šæ‰¬) | å˜´éƒ¨ |
| **AU14** | Dimpler (é…’çª) | å˜´éƒ¨ |
| **AU15** | Lip Corner Depressor (å˜´è§’ä¸‹æ‹‰) | å˜´éƒ¨ |
| **AU17** | Chin Raiser (ä¸‹å·´ä¸Šæ) | ä¸‹å·´ |
| **AU20** | Lip Stretcher (å˜´å”‡æ‹‰ä¼¸) | å˜´éƒ¨ |
| **AU23** | Lip Tightener (å˜´å”‡æ”¶ç´§) | å˜´éƒ¨ |
| **AU24** | Lip Pressor (å”‡éƒ¨å‹ç´§) | å˜´éƒ¨ |
| **AU25** | Lips Part (å˜´å”‡åˆ†å¼€) | å˜´éƒ¨ |
| **AU26** | Jaw Drop (ä¸‹é¢Œä¸‹é™) | ä¸‹é¢Œ |
| **AU28** | Lip Suck (å¸å˜´å”‡) | å˜´éƒ¨ |
| **AU43** | Eyes Closed (é—­çœ¼) | çœ¼ç› |

#### Emotions (7ä¸ª)
æ¯ä¸ªæƒ…ç»ªçš„æ¦‚ç‡ï¼Œå€¼åŸŸ: [0.0, 1.0]ï¼Œæ€»å’Œâ‰ˆ1.0

- **anger** (æ„¤æ€’)
- **disgust** (åŒæ¶)
- **fear** (ææƒ§)
- **happiness** (å¿«ä¹)
- **sadness** (æ‚²ä¼¤)
- **surprise** (æƒŠè®¶)
- **neutral** (ä¸­æ€§)

### ä½¿ç”¨åœºæ™¯
âœ… é€‚åˆï¼š**åºåˆ—æ¨¡å‹**
- LSTM, GRU, BiLSTM
- Transformer, Temporal Convolutional Networks (TCN)
- 1D CNN
- Attention-based models

ğŸ“Š **æ•°æ®æ ¼å¼**:
```python
# å½¢çŠ¶: (25920, 27)
# æ¯ä¸€è¡Œ = ä¸€å¸§çš„ç‰¹å¾
# å¯ä»¥reshapeä¸º: (42 clips, ~617 frames/clip, 27 features)
```

---

## 2ï¸âƒ£ Clip-level Simple Features (ç‰‡æ®µçº§åˆ«ç®€å•ç‰¹å¾)
**æ–‡ä»¶**: `clip_features_simple.csv`

### ç‰¹å¾ç»“æ„ (138ä¸ª)

å¯¹æ¯ä¸ªåŸå§‹ç‰¹å¾ï¼ˆ20ä¸ªAU + 7ä¸ªemotionï¼‰æå– **5ç§ç»Ÿè®¡é‡**:

| ç»Ÿè®¡é‡ | æè¿° | ç¤ºä¾‹ |
|--------|------|------|
| **mean** | å¹³å‡å€¼ | `AU01_mean` |
| **std** | æ ‡å‡†å·® | `AU01_std` |
| **min** | æœ€å°å€¼ | `AU01_min` |
| **max** | æœ€å¤§å€¼ | `AU01_max` |
| **median** | ä¸­ä½æ•° | `AU01_median` |

ğŸ“ **æ€»ç‰¹å¾æ•°**: 27 features Ã— 5 stats = **135 features** + 3 metadata = **138åˆ—**

### ç¤ºä¾‹ç‰¹å¾åˆ—
```
AU01_mean, AU01_std, AU01_min, AU01_max, AU01_median
AU02_mean, AU02_std, AU02_min, AU02_max, AU02_median
...
anger_mean, anger_std, anger_min, anger_max, anger_median
happiness_mean, happiness_std, happiness_min, happiness_max, happiness_median
neutral_mean, neutral_std, neutral_min, neutral_max, neutral_median
```

### ä½¿ç”¨åœºæ™¯
âœ… é€‚åˆï¼š**ä¼ ç»Ÿæœºå™¨å­¦ä¹ æ¨¡å‹**
- Random Forest
- XGBoost, LightGBM, CatBoost
- SVM
- Logistic Regression
- KNN

ğŸ’¡ **ä¼˜åŠ¿**: 
- å¿«é€Ÿè®­ç»ƒ
- å¯è§£é‡Šæ€§å¼º
- ä¸éœ€è¦å¤§é‡æ•°æ®

---

## 3ï¸âƒ£ Clip-level Full Engineered Features (ç‰‡æ®µçº§åˆ«å®Œæ•´å·¥ç¨‹ç‰¹å¾)
**æ–‡ä»¶**: `clip_features_full.csv`

### ç‰¹å¾åˆ†ç±» (562ä¸ª)

#### A. ç»Ÿè®¡ç‰¹å¾ (297ä¸ª)
å¯¹æ¯ä¸ªåŸå§‹ç‰¹å¾æå– **11ç§ç»Ÿè®¡é‡**:

| ç‰¹å¾ç±»å‹ | æ•°é‡ | æè¿° |
|----------|------|------|
| mean | 27 | å¹³å‡å€¼ |
| median | 27 | ä¸­ä½æ•° |
| std | 27 | æ ‡å‡†å·® |
| min | 27 | æœ€å°å€¼ |
| max | 27 | æœ€å¤§å€¼ |
| range | 27 | æå·® (max - min) |
| q25 | 27 | ç¬¬25ç™¾åˆ†ä½æ•° |
| q75 | 27 | ç¬¬75ç™¾åˆ†ä½æ•° |
| iqr | 27 | å››åˆ†ä½è· (q75 - q25) |
| skew | 27 | ååº¦ |
| kurtosis | 27 | å³°åº¦ |

**ç¤ºä¾‹**: `AU01_mean`, `AU01_std`, `AU01_skew`, `AU01_kurtosis`, `anger_median`, `happiness_iqr`

#### B. æ—¶åºç‰¹å¾ (216ä¸ª)
å¯¹æ¯ä¸ªåŸå§‹ç‰¹å¾æå– **8ç§åŠ¨æ€ç‰¹å¾**:

| ç‰¹å¾ç±»å‹ | æè¿° |
|----------|------|
| **mean_change** | ä¸€é˜¶å¯¼æ•°çš„å‡å€¼ (é€Ÿåº¦) |
| **std_change** | ä¸€é˜¶å¯¼æ•°çš„æ ‡å‡†å·® |
| **abs_change** | ç»å¯¹å˜åŒ–çš„å‡å€¼ |
| **mean_accel** | äºŒé˜¶å¯¼æ•°çš„å‡å€¼ (åŠ é€Ÿåº¦) |
| **std_accel** | äºŒé˜¶å¯¼æ•°çš„æ ‡å‡†å·® |
| **num_peaks** | å³°å€¼æ•°é‡ |
| **peak_prominence_mean** | å³°å€¼æ˜¾è‘—æ€§å‡å€¼ |
| **trend_slope** | çº¿æ€§è¶‹åŠ¿æ–œç‡ |
| **trend_r2** | è¶‹åŠ¿æ‹Ÿåˆåº¦ (RÂ²) |

**ç¤ºä¾‹**: `AU01_mean_change`, `AU01_num_peaks`, `AU01_trend_slope`, `happiness_mean_accel`

ğŸ’¡ è¿™äº›ç‰¹å¾å¯ä»¥æ•æ‰ï¼š
- è¡¨æƒ…å˜åŒ–é€Ÿåº¦
- è¡¨æƒ…å˜åŒ–å¹³æ»‘åº¦
- è¡¨æƒ…å¼ºåº¦è¶‹åŠ¿ï¼ˆä¸Šå‡/ä¸‹é™ï¼‰
- è¡¨æƒ…æ³¢åŠ¨é¢‘ç‡

#### C. AUç»„åˆç‰¹å¾ (8ä¸ª)
åŸºäºé¢éƒ¨åŒºåŸŸçš„ç»„åˆç‰¹å¾:

| ç‰¹å¾ | æè¿° |
|------|------|
| **upper_face_mean** | ä¸ŠåŠè„¸AUå¹³å‡æ¿€æ´» (AU01,02,04,05,06,07) |
| **upper_face_std** | ä¸ŠåŠè„¸AUæ¿€æ´»æ ‡å‡†å·® |
| **upper_face_max** | ä¸ŠåŠè„¸AUæœ€å¤§æ¿€æ´» |
| **lower_face_mean** | ä¸‹åŠè„¸AUå¹³å‡æ¿€æ´» (AU09-28) |
| **lower_face_std** | ä¸‹åŠè„¸AUæ¿€æ´»æ ‡å‡†å·® |
| **lower_face_max** | ä¸‹åŠè„¸AUæœ€å¤§æ¿€æ´» |
| **num_high_aus** | é«˜æ¿€æ´»AUæ•°é‡ (>0.5) |
| **au_diversity** | AUå¤šæ ·æ€§ (æ¿€æ´»AUæ•°é‡, >0.3) |

ğŸ’¡ è¿™äº›ç‰¹å¾å¯ä»¥åŒºåˆ†ï¼š
- çœ‰çœ¼è¡¨æƒ… vs å˜´éƒ¨è¡¨æƒ…
- è¡¨æƒ…å¤æ‚åº¦
- å¾®è¡¨æƒ… vs å¼ºçƒˆè¡¨æƒ…

#### D. æƒ…ç»ªç‰¹å¾ (10ä¸ª)
ä¸“é—¨é’ˆå¯¹æƒ…ç»ªçš„é«˜çº§ç‰¹å¾:

| ç‰¹å¾ | æè¿° |
|------|------|
| **freq_anger_dominant** | æ„¤æ€’ä¸ºä¸»å¯¼æƒ…ç»ªçš„å¸§å æ¯” |
| **freq_disgust_dominant** | åŒæ¶ä¸ºä¸»å¯¼æƒ…ç»ªçš„å¸§å æ¯” |
| **freq_fear_dominant** | ææƒ§ä¸ºä¸»å¯¼æƒ…ç»ªçš„å¸§å æ¯” |
| **freq_happiness_dominant** | å¿«ä¹ä¸ºä¸»å¯¼æƒ…ç»ªçš„å¸§å æ¯” |
| **freq_sadness_dominant** | æ‚²ä¼¤ä¸ºä¸»å¯¼æƒ…ç»ªçš„å¸§å æ¯” |
| **freq_surprise_dominant** | æƒŠè®¶ä¸ºä¸»å¯¼æƒ…ç»ªçš„å¸§å æ¯” |
| **freq_neutral_dominant** | ä¸­æ€§ä¸ºä¸»å¯¼æƒ…ç»ªçš„å¸§å æ¯” |
| **max_emotion_intensity** | æœ€å¤§æƒ…ç»ªå¼ºåº¦å‡å€¼ |
| **emotion_variability** | æƒ…ç»ªå˜åŒ–å¹…åº¦ |
| **expressiveness** | è¡¨è¾¾æ€§ (éä¸­æ€§å¸§å æ¯”) |

ğŸ’¡ è¿™äº›ç‰¹å¾å¯ä»¥è¯†åˆ«ï¼š
- æƒ…ç»ªç¨³å®šæ€§
- æƒ…ç»ªå¤šæ ·æ€§
- è¡¨æƒ…ä¸°å¯Œç¨‹åº¦

### ä½¿ç”¨åœºæ™¯
âœ… é€‚åˆï¼š**æ‰€æœ‰ç±»å‹çš„æ¨¡å‹**
- ä¼ ç»ŸML: RF, XGBoost, SVM (é€‰æ‹©é‡è¦ç‰¹å¾)
- æ·±åº¦å­¦ä¹ : MLP, AutoEncoder
- ç‰¹å¾é€‰æ‹©åç”¨äºä»»ä½•æ¨¡å‹

ğŸ’¡ **ä¼˜åŠ¿**: 
- ç‰¹å¾ä¸°å¯Œï¼Œä¿¡æ¯é‡å¤§
- åŒ…å«æ—¶åºåŠ¨æ€ä¿¡æ¯
- å¯ä»¥åšç‰¹å¾é€‰æ‹©/é™ç»´

---

## ğŸ¯ å»ºè®®çš„è®­ç»ƒç­–ç•¥

### æ–¹æ¡ˆ1: ä¼ ç»Ÿæœºå™¨å­¦ä¹  (é€‚åˆå°æ•°æ®é›†)
```python
# ä½¿ç”¨ clip_features_simple.csv æˆ– clip_features_full.csv
X = df.drop(['sample_id', 'video_id', 'clip_id'], axis=1)
y = your_labels  # ä½ çš„ç›®æ ‡å˜é‡

# æ¨¡å‹é€‰æ‹©
from sklearn.ensemble import RandomForestClassifier
from xgboost import XGBClassifier

model = RandomForestClassifier(n_estimators=100)
model = XGBClassifier(n_estimators=100)
```

**æ¨èç‰¹å¾ç»„åˆ**:
- å¼€å§‹: `clip_features_simple.csv` (138 features)
- è¿›é˜¶: `clip_features_full.csv` çš„ç»Ÿè®¡ç‰¹å¾ (297 features)
- é«˜çº§: `clip_features_full.csv` å…¨éƒ¨ç‰¹å¾ + ç‰¹å¾é€‰æ‹©

### æ–¹æ¡ˆ2: æ·±åº¦åºåˆ—æ¨¡å‹ (é€‚åˆæ•æ‰æ—¶åºä¿¡æ¯)
```python
# ä½¿ç”¨ combined_au_features.csv
# å°†æ•°æ®reshapeä¸ºåºåˆ—æ ¼å¼
# Shape: (num_clips, seq_length, num_features)

import torch
from torch import nn

class LSTMModel(nn.Module):
    def __init__(self, input_size=27, hidden_size=64):
        super().__init__()
        self.lstm = nn.LSTM(input_size, hidden_size, batch_first=True)
        self.fc = nn.Linear(hidden_size, num_classes)
    
    def forward(self, x):
        # x: (batch, seq_len, 27)
        _, (h_n, _) = self.lstm(x)
        return self.fc(h_n[-1])
```

### æ–¹æ¡ˆ3: æ··åˆæ–¹æ³•
```python
# 1. ç”¨ combined_au_features.csv è®­ç»ƒLSTMæå–åºåˆ—ç‰¹å¾
# 2. å°†LSTMçš„hidden statesä½œä¸ºæ–°ç‰¹å¾
# 3. ç»“åˆ clip_features_full.csv çš„ç»Ÿè®¡ç‰¹å¾
# 4. ç”¨XGBooståšæœ€ç»ˆé¢„æµ‹
```

---

## ğŸ” ç‰¹å¾é€‰æ‹©å»ºè®®

### å¦‚æœæ•°æ®é‡å° (< 1000 samples)
1. ä½¿ç”¨ `clip_features_simple.csv` (138 features)
2. æˆ–ä» `clip_features_full.csv` ä¸­é€‰æ‹©æœ€é‡è¦çš„ç‰¹å¾

### å¦‚æœæ•°æ®é‡ä¸­ç­‰ (1000-10000 samples)
1. ä½¿ç”¨ `clip_features_full.csv` å…¨éƒ¨ç‰¹å¾
2. åšç‰¹å¾é‡è¦æ€§åˆ†æ
3. ä¿ç•™ top 100-200 é‡è¦ç‰¹å¾

### å¦‚æœæ•°æ®é‡å¤§ (> 10000 samples)
1. å¯ä»¥ä½¿ç”¨ `combined_au_features.csv` è®­ç»ƒæ·±åº¦å­¦ä¹ æ¨¡å‹
2. æˆ–è€…ç”¨å…¨éƒ¨å·¥ç¨‹ç‰¹å¾ + ç‰¹å¾é€‰æ‹©

---

## ğŸ“Š ç‰¹å¾é‡è¦æ€§åˆ†æç¤ºä¾‹

```python
import pandas as pd
from sklearn.ensemble import RandomForestClassifier
import matplotlib.pyplot as plt

# åŠ è½½ç‰¹å¾
df = pd.read_csv('features/clip_features_full.csv')
X = df.drop(['sample_id', 'video_id', 'clip_id'], axis=1)
y = your_labels

# è®­ç»ƒæ¨¡å‹
model = RandomForestClassifier(n_estimators=100)
model.fit(X, y)

# è·å–ç‰¹å¾é‡è¦æ€§
feature_importance = pd.DataFrame({
    'feature': X.columns,
    'importance': model.feature_importances_
}).sort_values('importance', ascending=False)

# æŸ¥çœ‹top 20é‡è¦ç‰¹å¾
print(feature_importance.head(20))

# å¯è§†åŒ–
feature_importance.head(20).plot(x='feature', y='importance', kind='barh')
plt.show()
```

---

## ğŸ’¡ æœ€ä½³å®è·µ

### 1. **ä»ç®€å•å¼€å§‹**
- âœ… å…ˆç”¨ `clip_features_simple.csv`
- âœ… å»ºç«‹baselineæ¨¡å‹
- âœ… ç†è§£æ•°æ®åˆ†å¸ƒ

### 2. **é€æ­¥å¢åŠ å¤æ‚åº¦**
- âœ… å°è¯• `clip_features_full.csv`
- âœ… åšç‰¹å¾é€‰æ‹©
- âœ… å°è¯•ä¸åŒçš„æ¨¡å‹

### 3. **è€ƒè™‘æ—¶åºä¿¡æ¯**
- âœ… å¦‚æœä»»åŠ¡éœ€è¦æ•æ‰åŠ¨æ€å˜åŒ–ï¼Œç”¨ `combined_au_features.csv`
- âœ… ä½¿ç”¨LSTM/Transformerç­‰åºåˆ—æ¨¡å‹
- âœ… å¯ä»¥ç»“åˆé™æ€ç‰¹å¾å’Œåºåˆ—ç‰¹å¾

### 4. **ç‰¹å¾å·¥ç¨‹è¿­ä»£**
- âœ… åˆ†æå“ªäº›ç‰¹å¾å¯¹ä½ çš„ä»»åŠ¡æœ€é‡è¦
- âœ… åˆ›å»ºé¢†åŸŸç‰¹å®šçš„ç‰¹å¾
- âœ… åšç‰¹å¾äº¤äº’ (feature interactions)

---

## ğŸ“ ç¤ºä¾‹ä»£ç 

### åŠ è½½å’Œä½¿ç”¨ç®€å•ç‰¹å¾
```python
import pandas as pd
from sklearn.model_selection import train_test_split
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report

# åŠ è½½æ•°æ®
df = pd.read_csv('features/clip_features_simple.csv')

# åˆ†ç¦»ç‰¹å¾å’Œæ ‡ç­¾
X = df.drop(['sample_id', 'video_id', 'clip_id'], axis=1)
y = your_labels  # ä½ éœ€è¦æä¾›æ ‡ç­¾

# åˆ’åˆ†è®­ç»ƒ/æµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(
    X, y, test_size=0.2, random_state=42
)

# è®­ç»ƒæ¨¡å‹
model = RandomForestClassifier(n_estimators=100, random_state=42)
model.fit(X_train, y_train)

# è¯„ä¼°
y_pred = model.predict(X_test)
print(classification_report(y_test, y_pred))
```

### ä½¿ç”¨åºåˆ—ç‰¹å¾
```python
import pandas as pd
import numpy as np

# åŠ è½½frame-levelæ•°æ®
df = pd.read_csv('features/combined_au_features.csv')

# æå–ç‰¹å¾åˆ—
feature_cols = [col for col in df.columns if col.startswith('AU') or 
                col in ['anger', 'disgust', 'fear', 'happiness', 'sadness', 'surprise', 'neutral']]

# ä¸ºæ¯ä¸ªclipå‡†å¤‡åºåˆ—æ•°æ®
sequences = []
labels = []

for sample_id in df['sample_id'].unique():
    clip_df = df[df['sample_id'] == sample_id]
    sequence = clip_df[feature_cols].values  # shape: (num_frames, 27)
    sequences.append(sequence)
    labels.append(your_label_for_this_clip)

# è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆéœ€è¦paddingåˆ°ç›¸åŒé•¿åº¦ï¼‰
from tensorflow.keras.preprocessing.sequence import pad_sequences
X = pad_sequences(sequences, padding='post', dtype='float32')
y = np.array(labels)

# ç°åœ¨å¯ä»¥ç”¨äºè®­ç»ƒLSTMç­‰æ¨¡å‹
```

---

## ğŸ“ æ€»ç»“

| ç‰¹å¾æ–‡ä»¶ | æ ·æœ¬æ•° | ç‰¹å¾æ•° | æœ€ä½³ç”¨é€” |
|----------|--------|--------|----------|
| **combined_au_features.csv** | 25,920 | 27 | åºåˆ—æ¨¡å‹ (LSTM, Transformer) |
| **clip_features_simple.csv** | 42 | 138 | å¿«é€ŸåŸå‹ + ä¼ ç»ŸML |
| **clip_features_full.csv** | 42 | 562 | å®Œæ•´ç‰¹å¾å·¥ç¨‹ + é«˜çº§æ¨¡å‹ |

**å»ºè®®workflow**:
1. ä» `clip_features_simple.csv` å¼€å§‹å»ºç«‹baseline
2. å¦‚æœæ€§èƒ½ä¸å¤Ÿï¼Œå°è¯• `clip_features_full.csv`
3. å¦‚æœéœ€è¦æ•æ‰æ—¶åºåŠ¨æ€ï¼Œä½¿ç”¨ `combined_au_features.csv`
4. æ ¹æ®ç‰¹å¾é‡è¦æ€§åšç‰¹å¾é€‰æ‹©
5. å°è¯•ensembleå¤šä¸ªæ¨¡å‹

ç¥è®­ç»ƒé¡ºåˆ©ï¼ğŸš€

